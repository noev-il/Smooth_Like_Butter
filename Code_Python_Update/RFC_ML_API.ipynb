{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2bd38e-bfd6-4f4e-8b63-113d3a5e53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smooth' 'bad' 'bad']\n",
      "It took this long to run:  25.189762115478516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class tensor_creator:\n",
    "    def __init__(self, url_1, url_2):\n",
    "        self.client_id = \"76915a0c79a34e108e08ab4ca0e2605f\"\n",
    "        self.client_secret = \"f30900615bad41d0ae950d4e2ad72668\"\n",
    "        self.access_token = None\n",
    "        api_token = \"https://accounts.spotify.com/api/token\"\n",
    "        auth_string = f'{self.client_id}:{self.client_secret}'\n",
    "        auth_base64 = base64.b64encode(auth_string.encode()).decode('ascii')\n",
    "        token_data = {\n",
    "            \"grant_type\": \"client_credentials\"\n",
    "        }\n",
    "        token_headers = {\n",
    "            \"Authorization\": f\"Basic {auth_base64}\",\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "        }\n",
    "        req = requests.post(api_token, data=token_data, headers=token_headers)\n",
    "        token_response_data = req.json()\n",
    "        self.access_token = token_response_data.get('access_token')\n",
    "        self.url_1 = url_1[31:]\n",
    "        self.url_2 = url_2[31:]\n",
    "\n",
    "    def get_track_analysis(self, song_id):\n",
    "        token_live = self.access_token\n",
    "        if token_live:\n",
    "            api_token = f\"https://api.spotify.com/v1/audio-analysis/{song_id}\"\n",
    "            header_1 = {\n",
    "                \"Authorization\": f\"Bearer {token_live}\"\n",
    "            }\n",
    "            try:\n",
    "                response = requests.get(api_token, headers=header_1)\n",
    "                response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "                json_file = response.json()\n",
    "                return (json_file)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                return {\"Request failed\": e, \"Response content\": response.content}  # Print response content for debugging\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _make_tensor(self):\n",
    "        self.analysis_1 = self.get_track_analysis(self.url_1)\n",
    "        self.analysis_2 = self.get_track_analysis(self.url_2)\n",
    "        track_1 = self.analysis_1\n",
    "        track_2 = self.analysis_2\n",
    "        DATA_FRAME = []\n",
    "        Dictionary = {'start': [], 'duration': [], 'confidence': [], 'loudness': [], 'tempo': [], 'tempo_confidence': [], 'key': [], 'key_confidence': [], 'mode': [], 'mode_confidence': [], 'time_signature': [], 'time_signature_confidence': []}\n",
    "        new_tensor = None\n",
    "        Song_Tensor = []\n",
    "        Song_Tensor_1 = []\n",
    "        sections_1 = track_1['sections']\n",
    "        sections_2 = track_2['sections']\n",
    "        DATA_FRAME += [pd.DataFrame(sections_1)]\n",
    "        DATA_FRAME += [pd.DataFrame(sections_2)]\n",
    "        DATA_FRAME[0].columns = ['start', 'duration', 'confidence', 'loudness', 'tempo', 'tempo_confidence', 'key', 'key_confidence', 'mode', 'mode_confidence', 'time_signature', 'time_signature_confidence']\n",
    "        Dictionary['start'] += [torch.tensor(DATA_FRAME[0]['start'].values)]\n",
    "        Dictionary['duration'] += [torch.tensor(DATA_FRAME[0]['duration'].values)]\n",
    "        Dictionary['confidence'] += [torch.tensor(DATA_FRAME[0]['confidence'].values)]\n",
    "        Dictionary['loudness'] += [torch.tensor(DATA_FRAME[0]['loudness'].values)]\n",
    "        Dictionary['tempo'] += [torch.tensor(DATA_FRAME[0]['tempo'].values)]\n",
    "        Dictionary['tempo_confidence'] += [torch.tensor(DATA_FRAME[0]['tempo_confidence'].values)]\n",
    "        Dictionary['key'] += [torch.tensor(DATA_FRAME[0]['key'].values)]\n",
    "        Dictionary['key_confidence'] += [torch.tensor(DATA_FRAME[0]['key_confidence'].values)]\n",
    "        Dictionary['mode'] += [torch.tensor(DATA_FRAME[0]['mode'].values)]\n",
    "        Dictionary['mode_confidence'] += [torch.tensor(DATA_FRAME[0]['mode_confidence'].values)]\n",
    "        Dictionary['time_signature'] += [torch.tensor(DATA_FRAME[0]['time_signature'].values)]\n",
    "        Dictionary['time_signature_confidence'] += [torch.tensor(DATA_FRAME[0]['time_signature_confidence'].values)]\n",
    "        for y in range(len(DATA_FRAME[0])):\n",
    "            new_tensor = (DATA_FRAME[0]['loudness'][y], DATA_FRAME[0]['tempo'][y], DATA_FRAME[0]['key'][y], DATA_FRAME[0]['mode'][y])\n",
    "            new_tensor_real = torch.tensor(new_tensor)\n",
    "            Song_Tensor += [new_tensor_real]\n",
    "        DATA_FRAME[1].columns = ['start', 'duration', 'confidence', 'loudness', 'tempo', 'tempo_confidence', 'key', 'key_confidence', 'mode', 'mode_confidence', 'time_signature', 'time_signature_confidence']\n",
    "        Dictionary['start'] += [torch.tensor(DATA_FRAME[1]['start'].values)]\n",
    "        Dictionary['duration'] += [torch.tensor(DATA_FRAME[1]['duration'].values)]\n",
    "        Dictionary['confidence'] += [torch.tensor(DATA_FRAME[1]['confidence'].values)]\n",
    "        Dictionary['loudness'] += [torch.tensor(DATA_FRAME[1]['loudness'].values)]\n",
    "        Dictionary['tempo'] += [torch.tensor(DATA_FRAME[1]['tempo'].values)]\n",
    "        Dictionary['tempo_confidence'] += [torch.tensor(DATA_FRAME[1]['tempo_confidence'].values)]\n",
    "        Dictionary['key'] += [torch.tensor(DATA_FRAME[1]['key'].values)]\n",
    "        Dictionary['key_confidence'] += [torch.tensor(DATA_FRAME[1]['key_confidence'].values)]\n",
    "        Dictionary['mode'] += [torch.tensor(DATA_FRAME[1]['mode'].values)]\n",
    "        Dictionary['mode_confidence'] += [torch.tensor(DATA_FRAME[1]['mode_confidence'].values)]\n",
    "        Dictionary['time_signature'] += [torch.tensor(DATA_FRAME[1]['time_signature'].values)]\n",
    "        Dictionary['time_signature_confidence'] += [torch.tensor(DATA_FRAME[0]['time_signature_confidence'].values)]\n",
    "        for z in range(len(DATA_FRAME[1])):\n",
    "            new_tensor = (DATA_FRAME[1]['loudness'][z], DATA_FRAME[1]['tempo'][z], DATA_FRAME[1]['key'][z], DATA_FRAME[1]['mode'][z])\n",
    "            new_tensor_real = torch.tensor(new_tensor)\n",
    "            Song_Tensor_1 += [new_tensor_real]\n",
    "        distanceA1_A2 = torch.sqrt(torch.sum(torch.pow(torch.subtract(Song_Tensor[-1], Song_Tensor_1[0]), 2), dim=0))\n",
    "        self.distanceA1_A2 = (distanceA1_A2)\n",
    "\n",
    "    def _segment_analyzer(self):\n",
    "        segment_1 = self.analysis_1['segments']\n",
    "        segment_2 = self.analysis_2['segments']\n",
    "\n",
    "        DATA_FRAME_1 = [pd.DataFrame(segment_1[:15])]\n",
    "        pitches_1 = []\n",
    "        timbre_1 = []\n",
    "        pitches_2 = []\n",
    "        timbre_2 = []\n",
    "        DATA_FRAME_2 = [pd.DataFrame(segment_2[-15:])]\n",
    "        DATA_FRAME_1[0].columns = ['start', 'duration', 'confidence',\n",
    "                                   \"loudness_start\", \"loudness_max_time\",\n",
    "                                   \"loudness_max\", \"loudness_end\", \"pitches\",\n",
    "                                   \"timbre\"]\n",
    "        DATA_FRAME_2[0].columns = ['start', 'duration', 'confidence',\n",
    "                                   \"loudness_start\", \"loudness_max_time\",\n",
    "                                   \"loudness_max\", \"loudness_end\",\n",
    "                                   \"pitches\", \"timbre\"]\n",
    "        # return DATA_FRAME_1[0]['pitches'][-1]\n",
    "        for p in range(12):\n",
    "            pitches_1 += [torch.tensor(DATA_FRAME_1[0]['pitches'][p])] \n",
    "            pitches_2 += [torch.tensor(DATA_FRAME_2[0]['pitches'][p])] \n",
    "        for t in range(12):\n",
    "            timbre_1 += [torch.tensor(DATA_FRAME_1[0]['timbre'][t])] \n",
    "            timbre_2 += [torch.tensor(DATA_FRAME_2[0]['timbre'][t])] \n",
    "        pitches_dist = []\n",
    "        timbres_dist = []\n",
    "        for g in range(12):\n",
    "            pitches_dist += [torch.sqrt(torch.sum(torch.pow(torch.subtract(\n",
    "                pitches_1[g], pitches_2[g]), 2), dim=0))]\n",
    "            timbres_dist += [torch.sqrt(torch.sum(torch.pow(torch.subtract(\n",
    "                timbre_1[g], timbre_2[g]), 2), dim=0))]\n",
    "        tensor_values_p = [tensor.item() for tensor in pitches_dist]\n",
    "        tensor_values_t = [tensor.item() for tensor in timbres_dist]\n",
    "        average_p = torch.tensor(tensor_values_p).mean()\n",
    "        average_t = torch.tensor(tensor_values_t).mean()\n",
    "        return np.array([self.distanceA1_A2.item(), average_p.item(), average_t.item()])\n",
    "\n",
    "    def create_and_analyze(self):\n",
    "        self._make_tensor()\n",
    "        return self._segment_analyzer()\n",
    "\n",
    "\n",
    "good_transitions = [\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"4K09vJ27xCOreumtSuU6Ao?si=7bf160671b854579\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"1otG6j1WHNvl9WgXLWkHTo?si=a3575a900f3a4c6d\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"3Qa944OTMZkg8DHjET8JQv?si=696ddb4a9daf4a67\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"19QKaApDINxlRSKX3w1xSB?si=c9229546c6334acb\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"4XDpeWqPADoWRKcUY3dC84?si=04e5e2519d52466c\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"47gzGfR4JfKC6aT5lM0wpn?si=0e1b348a726140d4\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"6BbAFjOCHA1AknMtIu3VjZ?si=8aea2fbe31c84d5e\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"3d65swPOxko76ZQL5WEQfH?si=37614ad6886a4e54\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"55jQMevNp7aWtiW5LPlPoa?si=1f0e24819e5e48b9\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"0IpnZchq8ek2A6pGEP2Qb1?si=678492cafa964419\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"01JMnRUs2YOK6DDpdQASGY?si=fb31acb7005141ec\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"3yk7PJnryiJ8mAPqsrujzf?si=c2e7c1714e0048be\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"1eUGmzzvahJjOSWgDHuRlv?si=6acaaa380516451f\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"5fEB6ZmVkg63GZg9qO86jh?si=d702f883e6a74661\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"4cEqoGTqPRZy76Yl3ymj3V?si=607505ce0fd74ab9\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"5m0yZ33oOy0yYBtdTXuxQe?si=8b052f9f38154c31\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"1Vp4St7JcXaUoJcIahtf3L?si=d98cb80a21c5487e\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"2wAJTrFhCnQyNSD3oUgTZO?si=a3ab2a4160324e16\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"3eekarcy7kvN4yt5ZFzltW?si=54306b352bad438c\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"7nc7mlSdWYeFom84zZ8Wr8?si=ec12e794185a4c20\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"5TxRUOsGeWeRl3xOML59Ai?si=bddb01a23e8d46aa\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"44I7sqKYCAa7bQdVywkShO?si=24e88ed468cd44e1\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"1nXZnTALNXiPlvXotqHm66?si=2a4f84e61d0c4b1b\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"00imgaPlYRrMGn9o83hfmk?si=620b5c7eb048468d\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"432hUIl3ISDeytYW5XBQ5h?si=eb0bcaba494a4a13\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"7AzlLxHn24DxjgQX73F9fU?si=861375864d784288\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"37Nqx7iavZpotJSDXZWbJ3?si=8ad80be899b34af0\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"5yY9lUy8nbvjM1Uyo1Uqoc?si=728160360270434a\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"5d8yMIlqJH78lwOUP7T3oF?si=8fedd201833b46d5\",\n",
    "    \"https://open.spotify.com/track/\"\n",
    "    \"05grSYrVwYw58YMOdJceyz?si=c715abc806c84c5b\"\n",
    "         ]\n",
    "names = [\n",
    "    \"A1_Silk_Sonic_Intro_Analysis\",\n",
    "    \"A2_After_The_Storm_Analysis\",\n",
    "    \"B1_Woods_Mac_Miller_Analysis\",\n",
    "    \"B2_Alotta_Cake_Gunna\",\n",
    "    \"C1_November_Tyler_The_Creator\",\n",
    "    \"C2_03_Sainte\",\n",
    "    \"D1_Thru_My_Hair_Teo\",\n",
    "    \"D2_Screwed_Up_Teeze\",\n",
    "    \"E1_1997_Brock_Hampton\",\n",
    "    \"E2_Bean_Kobe_Uzi\",\n",
    "    \"F1_Grace_Lil_Baby\",\n",
    "    \"F2_Location_Playboi_Carti\",\n",
    "    \"G1_Girl_With_Tattoo_Miguel\",\n",
    "    \"G2_Break_From_Toronot_PartyNextDoor\",\n",
    "    \"H1_Only_One_Travis_Scott\",\n",
    "    \"H2_Low_Down_Lil_Baby\",\n",
    "    \"I1_The_New_Workout_Plan_Kanye\",\n",
    "    \"I2_Work_Out_Jcole\",\n",
    "    \"J1_Highest_In_The_Room_Travis_Scot\",\n",
    "    \"J2_Tell_Em_Cochise\",\n",
    "    \"K1_Are_We_Still_Friends_Tyler_The_Creator\",\n",
    "    \"K2_Hurricane_Kanye\",\n",
    "    \"L1_A_Boy_Is_A_Gun_Tyler_The_Creator\",\n",
    "    \"L2_Loose_Change_Brent_Faiyaz\",\n",
    "    \"M1_Wolvez_Kanye\",\n",
    "    \"M2_No_Idea_Don_Toliver\",\n",
    "    \"N1_Girls_Want_Girls_Drake\",\n",
    "    \"N2_Life_Is_Good_Drake\",\n",
    "    \"O1_Real_Kendrick\",\n",
    "    \"O2_Patience_Lil_Uzi_Vert\"]\n",
    "Dict_Names = {\n",
    "    \"A1_Silk_Sonic_Intro_Analysis\": None,\n",
    "    \"A2_After_The_Storm_Analysis\": None,\n",
    "    \"B1_Woods_Mac_Miller_Analysis\": None,\n",
    "    \"B2_Alotta_Cake_Gunna\": None,\n",
    "    \"C1_November_Tyler_The_Creator\": None,\n",
    "    \"C2_03_Sainte\": None,\n",
    "    \"D1_Thru_My_Hair_Teo\": None,\n",
    "    \"D2_Screwed_Up_Teeze\": None,\n",
    "    \"E1_1997_Brock_Hampton\": None,\n",
    "    \"E2_Bean_Kobe_Uzi\": None,\n",
    "    \"F1_Grace_Lil_Baby\": None,\n",
    "    \"F2_Location_Playboi_Carti\": None,\n",
    "    \"G1_Girl_With_Tattoo_Miguel\": None,\n",
    "    \"G2_Break_From_Toronot_PartyNextDoor\": None,\n",
    "    \"H1_Only_One_Travis_Scott\": None,\n",
    "    \"H2_Low_Down_Lil_Baby\": None,\n",
    "    \"I1_The_New_Workout_Plan_Kanye\": None,\n",
    "    \"I2_Work_Out_Jcole\": None,\n",
    "    \"J1_Highest_In_The_Room_Travis_Scot\": None,\n",
    "    \"J2_Tell_Em_Cochise\": None,\n",
    "    \"K1_Are_We_Still_Friends_Tyler_The_Creator\": None,\n",
    "    \"K2_Hurricane_Kanye\": None,\n",
    "    \"L1_A_Boy_Is_A_Gun_Tyler_The_Creator\": None,\n",
    "    \"L2_Loose_Change_Brent_Faiyaz\": None,\n",
    "    \"M1_Wolvez_Kanye\": None,\n",
    "    \"M2_No_Idea_Don_Toliver\": None,\n",
    "    \"N1_Girls_Want_Girls_Drake\": None,\n",
    "    \"N2_Life_Is_Good_Drake\": None,\n",
    "    \"O1_Real_Kendrick\": None,\n",
    "    \"O2_Patience_Lil_Uzi_Vert\": None\n",
    "}\n",
    "store_open = []\n",
    "for h in range(29):\n",
    "    if h % 2 == 0:\n",
    "        store_new = tensor_creator(good_transitions[h], good_transitions[h+1])\n",
    "        store_check = store_new.create_and_analyze()\n",
    "        Dict_Names[names[h]] = store_check\n",
    "        if h == 28:\n",
    "            Dict_Names[names[h+1]] = Dict_Names[names[h]]\n",
    "    else:\n",
    "        Dict_Names[names[h]] = Dict_Names[names[h-1]]\n",
    "running_db = pd.DataFrame(Dict_Names)\n",
    "\n",
    "numpy_arrays = []\n",
    "\n",
    "for k in range(len(names)):\n",
    "    if k % 2 == 0:\n",
    "        numpy_arrays += [np.array(Dict_Names[f'{names[k]}'])]\n",
    "    else:\n",
    "        None\n",
    "\n",
    "bad_1 = tensor_creator('https://open.spotify.com/track/'\n",
    "                       '2FDTHlrBguDzQkp7PVj16Q?si=3ad17825b4774244',\n",
    "                       'https://open.spotify.com/track/'\n",
    "                       '09FcXaLu1BdrRNgxyBi6p5?si=4b41dfb40c174e38')\n",
    "numpy_arrays += [bad_1.create_and_analyze()]\n",
    "bad_2 = tensor_creator('https://open.spotify.com/track/'\n",
    "                       '0XqCWpRB3DLSy0l9bFQ15A?si=4ebc0d0bb4b3446c',\n",
    "                       'https://open.spotify.com/track/'\n",
    "                       '0WCbhE2evMrIwRM0DlMy9k?si=389f63f89d194583')\n",
    "numpy_arrays += [bad_2.create_and_analyze()]\n",
    "bad_3 = tensor_creator('https://open.spotify.com/track/'\n",
    "                       '71SbmXsy5H0bqxJAVBcfsG?si=7692e0d63eea456e',\n",
    "                       'https://open.spotify.com/track/'\n",
    "                       '7uHF03xE84sQ5PicRNH3yu?si=d8903751e6be4e22')\n",
    "numpy_arrays += [bad_3.create_and_analyze()]\n",
    "bad_4 = tensor_creator('https://open.spotify.com/track/'\n",
    "                       '7KVPsVMOK3NL7subwJ0dZj?si=46893e8879074917',\n",
    "                       'https://open.spotify.com/track/'\n",
    "                       '1chxfk33LoVOznJiJ0WWPD?si=da93686c079e4d0c')\n",
    "numpy_arrays += [bad_4.create_and_analyze()]\n",
    "bad_5 = tensor_creator('https://open.spotify.com/track/'\n",
    "                       '421r1p6Uzy72gSOyWHpmdA?si=af4d8c4f6077495e',\n",
    "                       'https://open.spotify.com/track/'\n",
    "                       '2OaKHGvIxoOzIYjyMsxcT8?si=1b22b0e0a99a4f14')\n",
    "numpy_arrays += [bad_5.create_and_analyze()]\n",
    "y_train = ['smooth'] * 15\n",
    "y_train += ['bad'] * 5\n",
    "\n",
    "X_test = []\n",
    "test_1 = tensor_creator('https://open.spotify.com/track/'\n",
    "                        '26hOm7dTtBi0TdpDGl141t?si=c16c108e8410477c',\n",
    "                        'https://open.spotify.com/track/'\n",
    "                        '46NzAxDzsE443IsyZndZfP?si=acaed19953e04c25')\n",
    "X_test += [test_1.create_and_analyze()]\n",
    "test_2 = tensor_creator('https://open.spotify.com/track/'\n",
    "                        '7viEq8U0GgZf3v5m4BON3c?si=5c2e592fb9b142f4',\n",
    "                        'https://open.spotify.com/track/'\n",
    "                        '7EcE5yCPVZaZut1JqowbcI?si=cd49328b067748ab')\n",
    "X_test += [test_2.create_and_analyze()]\n",
    "test_3 = tensor_creator('https://open.spotify.com/track/'\n",
    "                        '7fEoXCZTZFosUFvFQg1BmW?si=9fb6dbbdb06e48f5',\n",
    "                        'https://open.spotify.com/track/'\n",
    "                        '3Iy4j2lCqW8BXGkFk21U6F?si=20634ba0b4cf4479')\n",
    "X_test += [test_3.create_and_analyze()]\n",
    "\n",
    "y_test = ['smooth', 'bad', 'bad']\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(numpy_arrays, y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44de8f-ed10-4db0-b52d-4be2e4b38ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
